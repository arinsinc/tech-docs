# Shortest Path Algorithms

## ğŸ“‹ Overview

**Shortest path algorithms** find the minimum-cost path between vertices in a weighted graph. These are fundamental algorithms in computer science with applications in routing, navigation, network optimization, and more. Different algorithms are optimal for different graph types and constraints.

**Difficulty Level**: ğŸ”´ Advanced

---

## ğŸ¯ Problem Categories

### Types of Shortest Path Problems

```
1. Single-Source Shortest Path (SSSP)
   From one vertex to all others
   Examples: Dijkstra, Bellman-Ford

2. Single-Pair Shortest Path
   From source to specific target
   Can use SSSP algorithms

3. All-Pairs Shortest Path (APSP)
   Between every pair of vertices
   Examples: Floyd-Warshall, Johnson's

4. Single-Destination Shortest Path
   All vertices to one destination
   Reverse edges, use SSSP
```

---

## ğŸš€ Dijkstra's Algorithm

### Core Concept

**Dijkstra's** finds shortest paths from a source to all vertices in graphs with **non-negative** edge weights. Uses greedy approach with priority queue.

**Key Idea**: Always process the closest unvisited vertex.

---

### Visual Example

```
Graph:
        2       3
    A ----â†’ B ----â†’ C
    |       |       â†‘
    1       4       |
    |       |       2
    â†“       â†“       |
    D ----â†’ E ------â”˜
        5

Find shortest paths from A
```

**Step-by-Step Execution**:

```
Initial State:
Distance: {A: 0, B: âˆ, C: âˆ, D: âˆ, E: âˆ}
Priority Queue: [(0, A)]
Visited: {}

Step 1: Process A (distance 0)
Update neighbors:
  B: 0 + 2 = 2
  D: 0 + 1 = 1
Distance: {A:0, B:2, D:1, C:âˆ, E:âˆ}
PQ: [(1,D), (2,B)]
Visited: {A}

        [0]
    A ----â†’ B
    |       
  [1]       
    |       
    â†“       
    D       

Step 2: Process D (distance 1)
Update neighbors:
  E: 1 + 5 = 6
Distance: {A:0, B:2, D:1, E:6, C:âˆ}
PQ: [(2,B), (6,E)]
Visited: {A, D}

Step 3: Process B (distance 2)
Update neighbors:
  C: 2 + 3 = 5
  E: 2 + 4 = 6 (not better than 6)
Distance: {A:0, B:2, D:1, E:6, C:5}
PQ: [(5,C), (6,E)]
Visited: {A, B, D}

Step 4: Process C (distance 5)
Update neighbors:
  (no outgoing edges)
Distance: {A:0, B:2, D:1, E:6, C:5}
PQ: [(6,E)]
Visited: {A, B, C, D}

Step 5: Process E (distance 6)
Update neighbors:
  C: 6 + 2 = 8 (worse than 5)
Final Distance: {A:0, B:2, D:1, E:6, C:5}
Visited: {A, B, C, D, E}
```

**Final Shortest Paths**:

```
A â†’ A: 0
A â†’ B: 2 (path: A â†’ B)
A â†’ C: 5 (path: A â†’ B â†’ C)
A â†’ D: 1 (path: A â†’ D)
A â†’ E: 6 (path: A â†’ D â†’ E)
```

---

### Path Reconstruction

```
Track parent pointers:

During algorithm:
When updating distance[v] via u:
  distance[v] = distance[u] + weight(u,v)
  parent[v] = u

After algorithm:
Reconstruct path from A to C:
C â†’ parent[C] = B
B â†’ parent[B] = A
A â†’ parent[A] = null

Path: A â†’ B â†’ C
```

---

### Why Greedy Works

```
Key Property: Non-negative weights

When we process vertex u with distance d:
- d is the shortest distance to u
- Any path through unprocessed vertices would be longer
  (because weights are non-negative)

Example:
    A --1-- B --(-5)-- C
    |                   â†‘
    10                  |
    â””-------------------â”˜

With negative weight:
Path Aâ†’Bâ†’C: 1 + (-5) = -4
Path Aâ†’C: 10

Greedy would choose B first (distance 1)
But better path exists through C!
âŒ Dijkstra fails with negative weights
```

---

### Complexity

- **Time**: O((V + E) log V) with binary heap priority queue
- **Time**: O(VÂ²) with array (dense graphs)
- **Time**: O(V + E) with Fibonacci heap (theoretical)
- **Space**: O(V) for distances, priority queue, visited set

```
Example:
V = 1000 vertices
E = 5000 edges

With binary heap:
O((1000 + 5000) Ã— log 1000) â‰ˆ 60,000 operations
```

---

## âš¡ Bellman-Ford Algorithm

### Core Concept

**Bellman-Ford** finds shortest paths from source to all vertices, works with **negative weights**, and **detects negative cycles**.

**Key Idea**: Relax all edges V-1 times.

---

### Visual Example

```
Graph with negative weight:
        2
    A ----â†’ B
    |       â†“
    4      -3
    â†“       â†“
    C â†---- D
        1

Find shortest paths from A
```

**Relaxation Process**:

```
Initial:
Distance: {A: 0, B: âˆ, C: âˆ, D: âˆ}

Iteration 1: Relax all edges
Edge Aâ†’B: dist[B] = min(âˆ, 0+2) = 2
Edge Aâ†’C: dist[C] = min(âˆ, 0+4) = 4
Edge Bâ†’D: dist[D] = min(âˆ, 2-3) = -1
Edge Dâ†’C: dist[C] = min(4, -1+1) = 0

After iteration 1:
Distance: {A:0, B:2, C:0, D:-1}

Iteration 2: Relax all edges
Edge Aâ†’B: dist[B] = min(2, 0+2) = 2 (no change)
Edge Aâ†’C: dist[C] = min(0, 0+4) = 0 (no change)
Edge Bâ†’D: dist[D] = min(-1, 2-3) = -1 (no change)
Edge Dâ†’C: dist[C] = min(0, -1+1) = 0 (no change)

After iteration 2:
Distance: {A:0, B:2, C:0, D:-1}

Iteration 3: (No changes)
Distance: {A:0, B:2, C:0, D:-1}

Final shortest distances:
Aâ†’A: 0
Aâ†’B: 2 (path: A â†’ B)
Aâ†’C: 0 (path: A â†’ B â†’ D â†’ C)
Aâ†’D: -1 (path: A â†’ B â†’ D)
```

---

### Negative Cycle Detection

```
Graph with negative cycle:
    A --1-- B
    |       |
    2      -5
    |       |
    C --1-- D

Cycle: A â†’ B â†’ D â†’ C â†’ A
Weight: 1 + (-5) + 1 + 2 = -1 < 0

After V-1 iterations:
Distance: {A:0, B:1, C:2, D:-4}

V-th iteration:
Edge Bâ†’D: dist[D] = min(-4, 1-5) = -6 (changed!)
Distance changed â†’ negative cycle detected!

Why negative cycles are problematic:
Can keep going around cycle to reduce distance infinitely
Shortest path undefined
```

---

### Why V-1 Iterations?

```
Maximum shortest path length = V-1 edges

Example: Linear graph
A â†’ B â†’ C â†’ D â†’ E (4 edges, 5 vertices)

Iteration 1: Aâ†’B shortest distance found
Iteration 2: Aâ†’Bâ†’C shortest distance found
Iteration 3: Aâ†’Bâ†’Câ†’D shortest distance found
Iteration 4: Aâ†’Bâ†’Câ†’Dâ†’E shortest distance found

After V-1 iterations, all shortest paths found
(if no negative cycles)
```

---

### Complexity

- **Time**: O(V Ã— E) - V-1 iterations, each processes all E edges
- **Space**: O(V) for distances array

```
Example:
V = 100 vertices
E = 500 edges

Time: 100 Ã— 500 = 50,000 operations
Much slower than Dijkstra!
```

---

## ğŸŒ Floyd-Warshall Algorithm

### Core Concept

**Floyd-Warshall** finds shortest paths between **all pairs** of vertices. Works with negative weights. Uses dynamic programming.

**Key Idea**: Consider paths through intermediate vertices k.

---

### Visual Example

```
Graph:
      3
  A ----â†’ B
  |       |
  2       1
  â†“       â†“
  C ----â†’ D
      4

Initial distance matrix (direct edges):
     A  B  C  D
A [  0  3  2  âˆ ]
B [  âˆ  0  âˆ  1 ]
C [  âˆ  âˆ  0  4 ]
D [  âˆ  âˆ  âˆ  0 ]
```

**Dynamic Programming Process**:

```
For k = 0 to V-1:
  For i = 0 to V-1:
    For j = 0 to V-1:
      dist[i][j] = min(dist[i][j], 
                       dist[i][k] + dist[k][j])

Meaning: Can we improve path iâ†’j by going through k?
```

**Step-by-Step**:

```
k=0 (intermediate vertex A):
Can A help any path?

i=B, j=C: Bâ†’C vs Bâ†’Aâ†’C
  âˆ vs (âˆ + 2) = no improvement
  
i=B, j=D: Bâ†’D vs Bâ†’Aâ†’D
  1 vs (âˆ + âˆ) = no improvement

After k=0:
     A  B  C  D
A [  0  3  2  âˆ ]
B [  âˆ  0  âˆ  1 ]
C [  âˆ  âˆ  0  4 ]
D [  âˆ  âˆ  âˆ  0 ]

k=1 (intermediate vertex B):
Can B help any path?

i=A, j=D: Aâ†’D vs Aâ†’Bâ†’D
  âˆ vs (3 + 1) = 4 âœ“ improvement!

After k=1:
     A  B  C  D
A [  0  3  2  4 ]
B [  âˆ  0  âˆ  1 ]
C [  âˆ  âˆ  0  4 ]
D [  âˆ  âˆ  âˆ  0 ]

k=2 (intermediate vertex C):
Can C help any path?

i=A, j=D: Aâ†’D vs Aâ†’Câ†’D
  4 vs (2 + 4) = 6 (no improvement)

After k=2:
     A  B  C  D
A [  0  3  2  4 ]
B [  âˆ  0  âˆ  1 ]
C [  âˆ  âˆ  0  4 ]
D [  âˆ  âˆ  âˆ  0 ]

k=3 (intermediate vertex D):
No improvements possible

Final matrix:
     A  B  C  D
A [  0  3  2  4 ]
B [  âˆ  0  âˆ  1 ]
C [  âˆ  âˆ  0  4 ]
D [  âˆ  âˆ  âˆ  0 ]
```

---

### Path Reconstruction

```
Maintain next[][] matrix:

Initially:
next[i][j] = j (direct edge)

When updating distance:
if dist[i][j] > dist[i][k] + dist[k][j]:
  dist[i][j] = dist[i][k] + dist[k][j]
  next[i][j] = next[i][k]

To get path from i to j:
path = [i]
while i != j:
  i = next[i][j]
  path.append(i)
```

---

### Negative Cycle Detection

```
After algorithm:
Check diagonal:
  if dist[i][i] < 0:
    negative cycle exists!

Example:
     A  B  C
A [  0  1  âˆ ]
B [  âˆ  0  -2]
C [  1  âˆ  0 ]

After Floyd-Warshall:
     A  B  C
A [  -1 0  -2]  â† dist[A][A] < 0
B [  -1 -2 -2]  â† dist[B][B] < 0
C [  0  1  -1]  â† dist[C][C] < 0

All vertices on negative cycle!
```

---

### Complexity

- **Time**: O(VÂ³) - three nested loops
- **Space**: O(VÂ²) for distance matrix

```
Example:
V = 100 vertices

Time: 100Â³ = 1,000,000 operations
Space: 100Â² = 10,000 entries

Good for dense graphs, small V
Not practical for large sparse graphs
```

---

## ğŸ¯ Algorithm Comparison

### When to Use Which

```
Dijkstra:
âœ“ Non-negative weights
âœ“ Single source
âœ“ Fast: O((V+E) log V)
âœ— Doesn't handle negative weights

Bellman-Ford:
âœ“ Handles negative weights
âœ“ Detects negative cycles
âœ“ Single source
âœ— Slow: O(VÃ—E)

Floyd-Warshall:
âœ“ All pairs shortest path
âœ“ Handles negative weights
âœ“ Simple to implement
âœ— Very slow: O(VÂ³)
âœ— High memory: O(VÂ²)
```

---

### Performance Comparison

```
Graph: V=1000, E=5000

Dijkstra (single source):
Time: (1000 + 5000) Ã— log(1000) â‰ˆ 60,000

Bellman-Ford (single source):
Time: 1000 Ã— 5000 = 5,000,000

Floyd-Warshall (all pairs):
Time: 1000Â³ = 1,000,000,000

Dijkstra Ã— 1000 (all pairs with non-negative):
Time: 60,000 Ã— 1000 = 60,000,000
(Still better than Floyd-Warshall!)
```

---

## ğŸ¨ Special Cases & Variations

### 1. A* Search

**Concept**: Dijkstra with heuristic guidance toward goal

```
Priority: g(n) + h(n)
g(n) = cost from start to n
h(n) = estimated cost from n to goal (heuristic)

Example: Map navigation
Heuristic = straight-line distance to destination

        [A]
       /   \
    5 /     \ 8
     /       \
   [B]       [C]
     \       /
    3 \     / 2
       \   /
        [Goal]

h(A) = 6, h(B) = 3, h(C) = 2

A* explores: A â†’ B â†’ Goal
(Ignores C due to heuristic)

Dijkstra would explore both paths
A* more efficient with good heuristic!
```

---

### 2. Bidirectional Dijkstra

**Concept**: Search from both source and target

```
Regular Dijkstra:
Source â†’ â†’ â†’ â†’ â†’ Target
(explore entire graph)

Bidirectional:
Source â†’ â†’ â† â† Target
(meet in middle)

Speedup: 2Ã— to 10Ã— in practice
```

---

### 3. SPFA (Shortest Path Faster Algorithm)

**Concept**: Optimization of Bellman-Ford using queue

```
Only relax edges from vertices whose distance changed

Queue: [A]
Distance: {A: 0, B: âˆ, C: âˆ}

Process A:
  Update B, C
  Queue: [B, C]

Process B:
  Update neighbors if improved
  
Average: O(E)
Worst: O(VÃ—E) (like Bellman-Ford)
```

---

## ğŸŒ Real-World Applications

### 1. GPS Navigation

```
Graph: Road network
Vertices: Intersections
Edges: Roads (weighted by distance/time)

Algorithm: Dijkstra or A*
Heuristic: Straight-line distance

Output: Turn-by-turn directions
```

### 2. Network Routing

```
Graph: Network topology
Vertices: Routers
Edges: Links (weighted by latency/bandwidth)

Algorithm: Dijkstra (OSPF protocol)

Dynamic: Recompute when network changes
```

### 3. Flight Itineraries

```
Graph: Flight network
Vertices: Airports
Edges: Flights (weighted by cost/time)

Algorithm: Dijkstra or Bellman-Ford
Constraints: Layover times, multiple criteria

Multi-criteria shortest path problem
```

### 4. Currency Arbitrage

```
Graph: Currency exchange
Vertices: Currencies
Edges: Exchange rates

Use negative log(rate):
Negative cycle = arbitrage opportunity!

Algorithm: Bellman-Ford
Detect profitable trading cycles
```

### 5. Social Networks

```
Graph: User connections
Vertices: Users
Edges: Friendships/follows

Find: Shortest path between users
"Degrees of separation"

Algorithm: BFS (unweighted) or Dijkstra
```

---

## ğŸ“ Key Takeaways

1. **Dijkstra**: Fast, non-negative weights, greedy approach
2. **Bellman-Ford**: Handles negatives, detects cycles, slower
3. **Floyd-Warshall**: All pairs, DP approach, O(VÂ³)
4. **Choose wisely**: Based on graph properties and requirements
5. **Optimization**: A*, bidirectional search for specific cases
6. **Real-world**: Routing, navigation, network protocols
7. **Tradeoffs**: Time vs space vs generality

---

## ğŸ’¡ Interview Tips

1. **Clarify weights**: Positive only? Negative weights? Cycles?
2. **Problem type**: Single-source or all-pairs?
3. **Graph size**: Small (Floyd-Warshall OK) or large?
4. **Discuss choices**: Why Dijkstra over Bellman-Ford?
5. **Edge cases**: Disconnected graph? Unreachable vertices?
6. **Optimization**: Can we use heuristics (A*)?
7. **Implementation**: Priority queue for Dijkstra essential

---

## ğŸ”— Related Topics

- [Graph Representations](./19_GRAPH_BASICS.md)
- [Graph Traversals](./20_GRAPH_TRAVERSALS.md)
- [Advanced Graph Algorithms](./22_ADVANCED_GRAPHS.md)
- [Priority Queues](./18_PRIORITY_QUEUES.md)

---

**Next**: [Advanced Graph Algorithms](./22_ADVANCED_GRAPHS.md)
